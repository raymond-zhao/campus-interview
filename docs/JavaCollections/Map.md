## HashMap

**put(K key, V val)**

1. 检查Hash桶数组是否为空或者长度为0，如果是的话则进行扩容操作
2. 根据 key 计算 hash 值，作为桶数组中的索引 i
3. 检查 table[i] 处是否为空
   1. 如果为空的话，则创建 Node 结点直接插入
   2. 如果非空的话，检查 key 是否存在，如果已存在，则为更新操作，直接覆盖
      1. 如果 key 不存在，检查 table[i] 是否是红黑树节点；
      2. 是的话则在红黑树中进行插入；
      3. 如果是链表，遍历链表寻找位置插入，此时链表长度不大于8，则进行插入或覆盖；
      4. 如果长度大于 8，则转换为红黑树再插入
4. 在 put 进值之后，将桶的数据容量+1，检查是否查过阈值需要扩容。
   1. 如果需要扩容则扩容
   2. 不需要扩容则结束

**get(K key)**

1. 根据 key 计算 hash 值，记索引为 i；
2. 检查 table 是否为空、长度是否大于0、并且 table[i] 中的第一个节点是否为空；
3. 如果 table 非空并且 table[i] 的第一个节点非空的话，则比较hash值、key值是否相等，相等的话则查到，直接返回；

4. 如果第一个节点不匹配的话，则检查是否是红黑树节点。
      1. 是红黑树节点则到红黑树中查找；
      2. 不是红黑树节点的话则遍历链表结点。
      3. 接下来无论是在红黑树中还是在链表中，都会对比 hash 值和 key 值，如果都匹配的话则说明查找到，返回。

5. 如果没查到的话，返回空。

**扩容**

1. 先引用保存扩容前的数组
2. 检查旧数组的容量是否已达到最大值，是则将阈值设置为 Integer 的最大值，并直接返回。
3. 否则的话，申请一个新容量的数组，执行 transfer() 方法，具体的是
   1. 遍历旧的数组，检查每一个桶是否为空，如果不为空的话，先把它保存一份，然后将其置空；
   2. 接着按保存下来的桶数组的头进行遍历，计算每一个结点在新数组中的位置；
   3. 最后将旧数组中的结点迁移到新数组中对应的位置。
4. 将旧数组的指针指向新数组
5. 计算新的阈值

## ConcurrentHashMap

初始化方法 `initTable()`

1. 首先检查`tab`是否为空，如果为空的话则尝试去初始化。
2. 检查`sizeCtl`是否小于 0，因为`sizeCtl` 的默认值为`0`，所以最先进入方法的一个或多个线程会尝试使用`CAS`去初始化数组，设置成功的话`sizeCtl=-1`，表示正在初始化，后续的线程将会进入调用`Thread.yield()`方法，由运行态转为就绪态。
3. 在将`sizeCtl`设置为 -1 后，会再次检查 `tab` 是否已被初始化，这是双端检锁的思想，避免`tab`被重复初始化。
4. 此时将会去设置指定容量的 Node 数组，默认为 16，并将成员变量`table`指向新创建的 Node 数组。
5. 接着降回去计算阈值，这里使用`sc=n - (n >>> 2);`，可以保证新的阈值=新容量*0.75。
6. 最后再更新`sizeCtl`，返回初始化后的`tab`。

`put(K key, V val)`

1. 检查`k-v`是否为`null`，是的话则抛出`NPE`。
2. 根据 `key` 计算 hash 值。
3. 检查 table 是否已被初始化，如果没有的话将会尝试去初始化，此时允许多个线程去尝试初始化，但是`initTable()`中的`CAS`操作保证了只有一个线程能够初始化成功。
4. 利用 `(n-1) & hash` 计算索引值，然后检查 `table` 中这个位置的首结点是否为空，为空的话则使用`CAS`尝试去设置值，设置成功则跳出。
5. 如果首结点不为空，说明发生了碰撞，这个时候将会使用`synchronized`去加锁头结点，但是不影响`table`中的其他 Node 的工作。接下来将会去判断加锁的头结点是属于链表结点还是红黑树节点。
   1. 如果是链表结点的话， 比较 key 和 hash 是否均相等，如果相等则进行覆盖，如果找到链表尾部 key 都不相等则在尾部进行插入(尾插法)。然后还要检查链表结点数量是否达到了树化阈值，是的话则进行树化。
   2. 如果是红黑树节点的话，则调用红黑树的操作进行节点插入，并进行相应地调整。
6. 如果此时进来的其他线程检查到正在扩容操作的话，将会去协助扩容，减少扩容时间。
7. 最后调用`addCount(1L, binCount)` 方法区近似地估计一下`table`中的总的元素数量。

`get(Object key)`

1. 根据 `key` 计算 哈希值
2. 检查`table`是否为空，非空的话检查`table`中根据`key`计算出的索引处的头结点也不为空
   1. 如果这两个检查中有一个为空，则返回`null`。
   2. 否则的话，检查定位到的头结点的 hash 与 key 是否均相等，相等的话则返回结果。
   3. 否则的话，判断是红黑树节点还是链表结点。如果是红黑树节点的话则到红黑树中查找，如果是链表结点的话则遍历链表查找，并返回相应的结果。
3. 如果最后没有查到，则返回 `null`。

`helpTransfer()`

`transfer()`方法为`CHM`扩容的核心方法。在此过程中，`CHM`支持多线程扩容。扩容主要分为两个步骤：

- 构建`nextTable`桶数组，大小为之前的两倍，这个操作在单线程下完成。
- 将`oldTable`里面的内容复制到`nextTable`，这个操作允许多线程操作。可以减少扩容时间。

基本思路与`HashMap`差不多，主要区别在于`CHM`多线程加锁`synchronized (f)`。

## CHM 如何保证线程安全

1. JDK1.8的 CHM 主要采用 `CAS + synchronized` 的方式锁住头结点，细化了锁的粒度。
2. JDK1.7的 CHM 主要采用 `Segment + synchronized` 分段锁实现了线程安全，这个内部类继承了`ReentrantLock`可重入锁这个类。每次加锁都会锁住`Segment`一个段，而一个`Segment`里包含了一个或多个`HashEntry`，锁的粒度较大。

## 为什么用了 synchronized 之后还要用 CAS 保证线程安全?



推荐阅读：[ConcurrentHashMap](https://raymond-zhao.top/2020/07/09/2020-07-09-JUC-ConcurrentHashMap/)

## HashMap、Hashtable、CHM区别

|      比较方面      |                 **HashMap**                 |                   **Hashtable**                   |                    **ConcurrentHashMap**                     |
| :----------------: | :-----------------------------------------: | :-----------------------------------------------: | :----------------------------------------------------------: |
|    是否线程安全    |                     否                      |                        是                         |                              是                              |
| 线程安全采用的方式 |                     无                      |          采用`synchronized`类锁，效率低           | `CAS` + `synchronized`，锁住的只有当前操作的**bucket**，不影响其他线程对其他bucket的操作，效率高 |
|      数据结构      |            数组 + 链表 + 红黑树             |                    数组 + 链表                    |                     数组 + 链表 + 红黑树                     |
| 是否允许`null`键值 |                     是                      |                        否                         |                              否                              |
|    哈希地址算法    |        `(h=key.hashCode())^(h>>>16`         |                 `key.hashCode()`                  |           `(h=key.hashCode())^(h>>>16)&0x7fffffff`           |
|      定位算法      |                `(n-1)&hash`                 |               `(hash&0x7fffffff)%n`               |                         `(n-1)&hash`                         |
|      扩容算法      | 当键值对数量大于阈值，则容量扩容到原来的2倍 | 当键值对数量大于等于阈值，则容量扩容到原来的2倍+1 | 当键值对数量大于等于sizeCtl，**单线程创建新哈希表，多线程复制bucket到新哈希表**，容量扩容到原来的2倍 |
|      链表插入      |         将新节点插入到链表**尾部**          |            将新节点插入到链表**头部**             |                  将新节点插入到链表**尾部**                  |
|      继承的类      |           继承`abstractMap`抽象类           |              继承`Dictionary`抽象类               |                   继承`abstractMap`抽象类                    |
|     实现的接口     |                实现`Map`接口                |                   实现`Map`接口                   |                   实现`ConcurrentMap`接口                    |
|    默认容量大小    |                     16                      |                        11                         |                              16                              |
|    默认负载因子    |                    0.75                     |                       0.75                        |                             0.75                             |
|   统计 size 方式   |           直接返回成员变量`size`            |              直接返回成员变量`count`              | 遍历`CounterCell`数组的值进行累加，最后加上`baseCount`的值即为`size` |

